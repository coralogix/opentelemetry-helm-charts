---
# Source: opentelemetry-collector/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: aml-opentelemetry-collector
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-collector-0.117.3
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: aml
    app.kubernetes.io/version: "0.129.1"
    app.kubernetes.io/managed-by: Helm
---
# Source: opentelemetry-collector/templates/configmap-agent.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: aml-opentelemetry-collector-agent
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-collector-0.117.3
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: aml
    app.kubernetes.io/version: "0.129.1"
    app.kubernetes.io/managed-by: Helm
    
data:
  relay: |
    connectors:
      forward/db: {}
      spanmetrics:
        dimensions:
        - name: http.method
        - name: cgx.transaction
        - name: cgx.transaction.root
        - name: status_code
        - name: db.namespace
        - name: db.operation.name
        - name: db.collection.name
        - name: db.system
        - name: http.response.status_code
        - name: rpc.grpc.status_code
        - name: service.version
        histogram:
          explicit:
            buckets:
            - 1ms
            - 4ms
            - 10ms
            - 20ms
            - 50ms
            - 100ms
            - 200ms
            - 500ms
            - 1s
            - 2s
            - 5s
        metrics_expiration: 0
        metrics_flush_interval: 15s
        namespace: ""
      spanmetrics/db:
        dimensions:
        - name: db.namespace
        - name: db.operation.name
        - name: db.collection.name
        - name: db.system
        - name: service.version
        histogram:
          explicit:
            buckets:
            - 100us
            - 1ms
            - 2ms
            - 2.5ms
            - 4ms
            - 6ms
            - 10ms
            - 100ms
            - 250ms
        metrics_expiration: 0
        metrics_flush_interval: 15s
        namespace: db
    exporters:
      coralogix/resource_catalog:
        application_name: resource
        domain: eu2.coralogix.com
        logs:
          headers:
            X-Coralogix-Distribution: helm-otel-integration/
            x-coralogix-ingress: metadata-as-otlp-logs/v1
        private_key: ${CORALOGIX_PRIVATE_KEY}
        subsystem_name: catalog
        timeout: 30s
      debug: {}
    extensions:
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
      k8s_observer:
        auth_type: serviceAccount
        observe_pods: true
    processors:
      filter/db_spanmetrics:
        traces:
          span:
          - attributes["db.system"] == nil
      filter/k8s_extra_metrics:
        metrics:
          metric:
          - resource.attributes["service.name"] == "kubernetes-apiserver" and name !=
            "kubernetes_build_info"
          - resource.attributes["service.name"] == "kubernetes-cadvisor" and (name !=
            "container_fs_writes_total" and name != "container_fs_reads_total" and name
            != "container_fs_writes_bytes_total" and name != "container_fs_reads_bytes_total"
            and name != "container_fs_usage_bytes" and name != "container_cpu_cfs_throttled_periods_total"
            and name != "container_cpu_cfs_periods_total")
      filter/workflow:
        error_mode: silent
        logs:
          log_record:
          - body["object"]["kind"] == "Pod" and not IsMatch(String(body["object"]["metadata"]["ownerReferences"]),
            ".*StatefulSet.*|.*ReplicaSet.*|.*Job.*|.*DaemonSet.*")
          - body["kind"] == "Pod" and not IsMatch(String(body["metadata"]["ownerReferences"]),
            ".*StatefulSet.*|.*ReplicaSet.*|.*Job.*|.*DaemonSet.*")
      k8sattributes:
        extract:
          metadata:
          - k8s.namespace.name
          - k8s.replicaset.name
          - k8s.statefulset.name
          - k8s.daemonset.name
          - k8s.cronjob.name
          - k8s.job.name
          - k8s.node.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.pod.start_time
        filter:
          node_from_env_var: K8S_NODE_NAME
        passthrough: false
        pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.ip
        - sources:
          - from: resource_attribute
            name: k8s.pod.uid
        - sources:
          - from: connection
        - sources:
          - from: resource_attribute
            name: k8s.job.name
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      redaction/metrics:
        allow_all_keys: false
        allowed_keys:
        - os.type
        - host.id
        - k8s.job.name
        - k8s.pod.uid
        - k8s.pod.start_time
        - k8s.node.name
        - k8s.namespace.name
        - k8s.pod.name
        - k8s.cronjob.name
        - k8s.replicaset.name
        - k8s.statefulset.name
        - k8s.daemonset.name
        summary: silent
      resource/metadata:
        attributes:
        - action: upsert
          key: k8s.cluster.name
          value: 'douglas-kind-test'
        - action: upsert
          key: cx.otel_integration.name
          value: coralogix-integration-helm
      resourcedetection/resource_catalog:
        azure:
          resource_attributes:
            azure.resourcegroup.name:
              enabled: false
            azure.vm.name:
              enabled: false
            azure.vm.scaleset.name:
              enabled: false
            azure.vm.size:
              enabled: false
            host.id:
              enabled: false
            host.name:
              enabled: false
        detectors:
        - eks
        - aks
        - gcp
        - ec2
        - azure
        ec2:
          resource_attributes:
            host.id:
              enabled: false
            host.image.id:
              enabled: false
            host.name:
              enabled: false
            host.type:
              enabled: false
        gcp:
          resource_attributes:
            host.id:
              enabled: false
            host.name:
              enabled: false
            host.type:
              enabled: false
            k8s.cluster.name:
              enabled: false
        override: true
        timeout: 2s
      transform/entity-event:
        error_mode: silent
        log_statements:
        - context: log
          statements:
          - set(attributes["otel.entity.interval"], Milliseconds(Duration("1h")))
      transform/k8s_attributes:
        log_statements:
        - context: resource
          statements:
          - set(attributes["k8s.deployment.name"], attributes["k8s.replicaset.name"])
          - replace_pattern(attributes["k8s.deployment.name"], "^(.*)-[0-9a-zA-Z]+$",
            "$$1") where attributes["k8s.replicaset.name"] != nil
          - delete_key(attributes, "k8s.replicaset.name")
        metric_statements:
        - context: resource
          statements:
          - set(attributes["k8s.deployment.name"], attributes["k8s.replicaset.name"])
          - replace_pattern(attributes["k8s.deployment.name"], "^(.*)-[0-9a-zA-Z]+$",
            "$$1") where attributes["k8s.replicaset.name"] != nil
          - delete_key(attributes, "k8s.replicaset.name")
        trace_statements:
        - context: resource
          statements:
          - set(attributes["k8s.deployment.name"], attributes["k8s.replicaset.name"])
          - replace_pattern(attributes["k8s.deployment.name"], "^(.*)-[0-9a-zA-Z]+$",
            "$$1") where attributes["k8s.replicaset.name"] != nil
          - delete_key(attributes, "k8s.replicaset.name")
      transform/prometheus:
        error_mode: ignore
        metric_statements:
        - context: metric
          statements:
          - replace_pattern(name, "_total$", "") where resource.attributes["service.name"]
            == "opentelemetry-collector"
        - context: resource
          statements:
          - set(attributes["k8s.pod.ip"], attributes["net.host.name"]) where attributes["service.name"]
            == "opentelemetry-collector"
          - delete_key(attributes, "service_name") where attributes["service.name"] ==
            "opentelemetry-collector"
        - context: datapoint
          statements:
          - delete_key(attributes, "service_name") where resource.attributes["service.name"]
            == "opentelemetry-collector"
          - delete_key(attributes, "otel_scope_name") where attributes["service.name"]
            == "opentelemetry-collector"
      transform/spanmetrics:
        error_mode: silent
        trace_statements:
        - context: span
          statements:
          - set(attributes["db.namespace"], attributes["db.name"]) where attributes["db.namespace"]
            == nil
          - set(attributes["db.namespace"], attributes["server.address"]) where attributes["db.namespace"]
            == nil
          - set(attributes["db.namespace"], attributes["network.peer.name"]) where attributes["db.namespace"]
            == nil
          - set(attributes["db.namespace"], attributes["net.peer.name"]) where attributes["db.namespace"]
            == nil
          - set(attributes["db.namespace"], attributes["db.system"]) where attributes["db.namespace"]
            == nil
          - set(attributes["db.operation.name"], attributes["db.operation"]) where attributes["db.operation.name"]
            == nil
          - set(attributes["db.collection.name"], attributes["db.sql.table"]) where attributes["db.collection.name"]
            == nil
          - set(attributes["db.collection.name"], attributes["db.cassandra.table"]) where
            attributes["db.collection.name"] == nil
          - set(attributes["db.collection.name"], attributes["db.mongodb.collection"])
            where attributes["db.collection.name"] == nil
          - set(attributes["db.collection.name"], attributes["db.redis.database_index"])
            where attributes["db.collection.name"] == nil
          - set(attributes["db.collection.name"], attributes["db.elasticsearch.path_parts.index"])
            where attributes["db.collection.name"] == nil
          - set(attributes["db.collection.name"], attributes["db.cosmosdb.container"])
            where attributes["db.collection.name"] == nil
          - set(attributes["db.collection.name"], attributes["aws_dynamodb.table_names"])
            where attributes["db.collection.name"] == nil
    receivers:
      filelog:
        exclude:
        - /var/log/pods/default_aml-opentelemetry-collector*_*/opentelemetry-collector/*.log
        force_flush_period: 0
        include:
        - /var/log/pods/*/*/*.log
        include_file_name: false
        include_file_path: true
        operators:
        - id: get-format
          routes:
          - expr: body matches "^\\{"
            output: parser-docker
          - expr: body matches "^[^ Z]+ "
            output: parser-crio
          - expr: body matches "^[^ Z]+Z"
            output: parser-containerd
          type: router
        - id: parser-crio
          regex: ^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
          timestamp:
            layout: 2006-01-02T15:04:05.999999999Z07:00
            layout_type: gotime
            parse_from: attributes.time
          type: regex_parser
        - combine_field: attributes.log
          combine_with: ""
          id: crio-recombine
          is_last_entry: attributes.logtag == 'F'
          max_batch_size: 1000
          max_log_size: 1048576
          output: handle_empty_log
          source_identifier: attributes["log.file.path"]
          type: recombine
        - id: parser-containerd
          regex: ^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: attributes.time
          type: regex_parser
        - combine_field: attributes.log
          combine_with: ""
          id: containerd-recombine
          is_last_entry: attributes.logtag == 'F'
          max_batch_size: 1000
          max_log_size: 1048576
          output: handle_empty_log
          source_identifier: attributes["log.file.path"]
          type: recombine
        - id: parser-docker
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: attributes.time
          type: json_parser
        - combine_field: attributes.log
          combine_with: ""
          id: docker-recombine
          is_last_entry: attributes.log endsWith "\n"
          max_batch_size: 1000
          max_log_size: 1048576
          output: handle_empty_log
          source_identifier: attributes["log.file.path"]
          type: recombine
        - field: attributes.log
          id: handle_empty_log
          if: attributes.log == nil
          type: add
          value: ""
        - parse_from: attributes["log.file.path"]
          regex: ^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]+)\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$
          type: regex_parser
        - from: attributes.stream
          to: attributes["log.iostream"]
          type: move
        - from: attributes.container_name
          to: resource["k8s.container.name"]
          type: move
        - from: attributes.namespace
          to: resource["k8s.namespace.name"]
          type: move
        - from: attributes.pod_name
          to: resource["k8s.pod.name"]
          type: move
        - from: attributes.restart_count
          to: resource["k8s.container.restart_count"]
          type: move
        - from: attributes.uid
          to: resource["k8s.pod.uid"]
          type: move
        - default: clean-up-log-record
          routes:
          - expr: (resource["k8s.namespace.name"]) == "kube-system" && (resource["k8s.pod.name"])
              matches "app-.*" && (resource["k8s.container.name"]) == "http"
            output: kube-system_app-.*_http
          type: router
        - combine_field: attributes.log
          combine_with: ""
          id: kube-system_app-.*_http
          is_first_entry: (attributes.log) matches "^[^\\s].*"
          max_batch_size: 1000
          max_log_size: 1048576
          max_unmatched_batch_size: 1
          output: clean-up-log-record
          source_identifier: attributes["log.file.path"]
          type: recombine
        - from: attributes.log
          id: clean-up-log-record
          to: body
          type: move
        retry_on_failure:
          enabled: true
        start_at: beginning
      k8sobjects/resource_catalog:
        objects:
        - group: ""
          mode: pull
          name: namespaces
        - group: ""
          mode: pull
          name: nodes
        - group: ""
          mode: pull
          name: persistentvolumeclaims
        - group: ""
          mode: pull
          name: persistentvolumes
        - group: ""
          mode: pull
          name: pods
        - group: ""
          mode: pull
          name: services
        - group: apps
          mode: pull
          name: daemonsets
        - group: apps
          mode: pull
          name: deployments
        - group: apps
          mode: pull
          name: replicasets
        - group: apps
          mode: pull
          name: statefulsets
        - group: autoscaling
          mode: pull
          name: horizontalpodautoscalers
        - group: batch
          mode: pull
          name: cronjobs
        - group: batch
          mode: pull
          name: jobs
        - group: extensions
          mode: pull
          name: ingresses
        - group: networking.k8s.io
          mode: pull
          name: ingresses
        - group: policy
          mode: pull
          name: poddisruptionbudgets
        - group: rbac.authorization.k8s.io
          mode: pull
          name: clusterrolebindings
        - group: rbac.authorization.k8s.io
          mode: pull
          name: clusterroles
        - group: rbac.authorization.k8s.io
          mode: pull
          name: rolebindings
        - group: rbac.authorization.k8s.io
          mode: pull
          name: roles
        - group: ""
          mode: watch
          name: namespaces
        - group: ""
          mode: watch
          name: nodes
        - group: ""
          mode: watch
          name: persistentvolumeclaims
        - group: ""
          mode: watch
          name: persistentvolumes
        - group: ""
          mode: watch
          name: pods
        - group: apps
          mode: watch
          name: daemonsets
        - group: apps
          mode: watch
          name: deployments
        - group: apps
          mode: watch
          name: replicasets
        - group: apps
          mode: watch
          name: statefulsets
        - group: autoscaling
          mode: watch
          name: horizontalpodautoscalers
        - group: batch
          mode: watch
          name: cronjobs
        - group: batch
          mode: watch
          name: jobs
        - group: extensions
          mode: watch
          name: ingresses
        - group: networking.k8s.io
          mode: watch
          name: ingresses
        - group: policy
          mode: watch
          name: poddisruptionbudgets
        - group: rbac.authorization.k8s.io
          mode: watch
          name: clusterrolebindings
        - group: rbac.authorization.k8s.io
          mode: watch
          name: clusterroles
        - group: rbac.authorization.k8s.io
          mode: watch
          name: rolebindings
        - group: rbac.authorization.k8s.io
          mode: watch
          name: roles
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
            max_recv_msg_size_mib: 20
          http:
            endpoint: ${env:MY_POD_IP}:4318
      prometheus:
        config:
          scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 30s
            static_configs:
            - targets:
              - ${env:MY_POD_IP}:8888
      prometheus/k8s_extra_metrics:
        config:
          scrape_configs:
          - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            honor_timestamps: true
            job_name: kubernetes-apiserver
            kubernetes_sd_configs:
            - role: endpoints
            relabel_configs:
            - action: keep
              regex: default;kubernetes;https
              source_labels:
              - __meta_kubernetes_namespace
              - __meta_kubernetes_service_name
              - __meta_kubernetes_endpoint_port_name
            scheme: https
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              insecure_skip_verify: true
          - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            honor_timestamps: true
            job_name: kubernetes-cadvisor
            kubernetes_sd_configs:
            - role: node
            metrics_path: /metrics/cadvisor
            relabel_configs:
            - action: labelmap
              regex: __meta_kubernetes_node_label_(.+)
            scheme: https
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              insecure_skip_verify: true
    service:
      extensions:
      - health_check
      - k8s_observer
      pipelines:
        logs:
          exporters:
          - debug
          processors:
          - memory_limiter
          - resource/metadata
          - k8sattributes
          - transform/k8s_attributes
          receivers:
          - filelog
          - otlp
        logs/resource_catalog:
          exporters:
          - coralogix/resource_catalog
          processors:
          - memory_limiter
          - resourcedetection/resource_catalog
          - transform/entity-event
          - filter/workflow
          - resource/metadata
          - batch
          receivers:
          - k8sobjects/resource_catalog
        metrics:
          exporters:
          - debug
          processors:
          - memory_limiter
          - resource/metadata
          - k8sattributes
          - transform/k8s_attributes
          - filter/k8s_extra_metrics
          - redaction/metrics
          - transform/prometheus
          receivers:
          - prometheus/k8s_extra_metrics
          - spanmetrics
          - spanmetrics/db
          - prometheus
          - otlp
        traces:
          exporters:
          - debug
          - spanmetrics
          - forward/db
          processors:
          - memory_limiter
          - resource/metadata
          - k8sattributes
          - transform/k8s_attributes
          - transform/spanmetrics
          receivers:
          - otlp
        traces/db:
          exporters:
          - spanmetrics/db
          processors:
          - filter/db_spanmetrics
          - batch
          receivers:
          - forward/db
      telemetry:
        logs:
          encoding: json
        metrics:
          readers:
          - pull:
              exporter:
                prometheus:
                  host: ${env:MY_POD_IP}
                  port: 8888
        resource:
          cx.agent.type: cluster-collector
          cx.cluster.name: 'douglas-kind-test'
          helm.chart.opentelemetry-collector.version: 0.117.3
          k8s.daemonset.name: aml-opentelemetry-collector
          k8s.namespace.name: default
          k8s.node.name: ${env:KUBE_NODE_NAME}
          k8s.pod.name: ${env:KUBE_POD_NAME}
          service.name: opentelemetry-collector
---
# Source: opentelemetry-collector/templates/configmap-supervisor.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: aml-opentelemetry-collector-supervisor
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-collector-0.117.3
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: aml
    app.kubernetes.io/version: "0.129.1"
    app.kubernetes.io/managed-by: Helm
    
data:
  supervisor.yaml: |
    server:
      endpoint: "https://ingress.eu2.coralogix.com/opamp/v1"
      headers:
        Authorization: "Bearer ${env:CORALOGIX_PRIVATE_KEY}"

    capabilities:
      reports_effective_config: true
      reports_own_metrics: true
      reports_own_logs: true
      reports_own_traces: true
      reports_health: true
      accepts_remote_config: true
      reports_remote_config: true

    agent:
      executable: /otelcol-contrib
      passthrough_logs: true
      # This passes config files to the Collector.
      config_files:
      - /conf/relay.yaml

      # This adds CLI arguments to the Collector.
      args: []

      # This adds env vars to the Collector process.
      env: {}

      description:
        non_identifying_attributes:
          k8s.daemonset.name: "aml-opentelemetry-collector"
          k8s.namespace.name: "default"
          k8s.node.name: ${env:KUBE_NODE_NAME}
          k8s.pod.name: ${env:KUBE_POD_NAME}
          service.name: "opentelemetry-collector"
          cx.agent.type: "cluster-collector"
          cx.cluster.name: "{{.Values.global.clusterName}}"

    # The storage can be used for many things:
    # - It stores configuration sent by the OpAMP server so that new collector
    #   processes can start with the most known desired config.
    storage:
      directory: /etc/otelcol-contrib/supervisor-data/

    telemetry:
      logs:
        level: warn
---
# Source: opentelemetry-collector/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: aml-opentelemetry-collector
  labels:
    helm.sh/chart: opentelemetry-collector-0.117.3
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: aml
    app.kubernetes.io/version: "0.129.1"
    app.kubernetes.io/managed-by: Helm
    
rules:
  - apiGroups: [""]
    resources: ["pods", "namespaces"]
    verbs: ["get", "watch", "list"]
  - apiGroups: ["apps"]
    resources: ["replicasets"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["extensions"]
    resources: ["replicasets"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["pods", "endpoints", "nodes/stats", "nodes/metrics", "nodes", "services"]
    verbs: ["get", "watch", "list"]
  - nonResourceURLs:
    - "/metrics"
    verbs: ["get"]
  - apiGroups: ["events.k8s.io"]
    resources: ["events"]
    verbs: ["watch", "list"]
  - apiGroups: [""]
    resources: ["configmaps"]
    resourceNames: ["aws-auth"]
    verbs: ["get"]
  - apiGroups: [""]
    resources:
    - namespaces
    - nodes
    - persistentvolumeclaims
    - persistentvolumes
    - pods
    - services
    verbs: ["get", "list", "watch"]
  - apiGroups: ["apps"]
    resources:
    - daemonsets
    - deployments
    - replicasets
    - statefulsets
    verbs: ["get", "list", "watch"]
  - apiGroups: ["autoscaling"]
    resources:
    - horizontalpodautoscalers
    verbs: ["get", "list", "watch"]
  - apiGroups: ["batch"]
    resources:
    - cronjobs
    - jobs
    verbs: ["get", "list", "watch"]
  - apiGroups: ["extensions"]
    resources:
    - ingresses
    verbs: ["get", "list", "watch"]
  - apiGroups: ["networking.k8s.io"]
    resources:
    - ingresses
    verbs: ["get", "list", "watch"]
  - apiGroups: ["policy"]
    resources:
    - poddisruptionbudgets
    verbs: ["get", "list", "watch"]
  - apiGroups: ["rbac.authorization.k8s.io"]
    resources:
    - clusterrolebindings
    - clusterroles
    - rolebindings
    - roles
    verbs: ["get", "list", "watch"]
---
# Source: opentelemetry-collector/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: aml-opentelemetry-collector
  labels:
    helm.sh/chart: opentelemetry-collector-0.117.3
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: aml
    app.kubernetes.io/version: "0.129.1"
    app.kubernetes.io/managed-by: Helm
    
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: aml-opentelemetry-collector
subjects:
- kind: ServiceAccount
  name: aml-opentelemetry-collector
  namespace: default
---
# Source: opentelemetry-collector/templates/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: aml-opentelemetry-collector-agent
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-collector-0.117.3
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: aml
    app.kubernetes.io/version: "0.129.1"
    app.kubernetes.io/managed-by: Helm
    
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: opentelemetry-collector
      app.kubernetes.io/instance: aml
      component: agent-collector
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: fb23a3f2802a0a47b2c77e356f3c501c436cd4d4b6111cbbaef49be508c457fd
        
      labels:
        app.kubernetes.io/name: opentelemetry-collector
        app.kubernetes.io/instance: aml
        component: agent-collector
        
    spec:
      
      serviceAccountName: aml-opentelemetry-collector
      securityContext:
        {}
      containers:
        - name: opentelemetry-collector
          command:
            - /opampsupervisor
            - --config=/etc/otelcol-contrib/supervisor.yaml
          securityContext:
            {}
          image: "coralogixrepo/otel-supervised-collector:latest"
          imagePullPolicy: IfNotPresent
          ports:
            
              
            - name: otlp
              containerPort: 4317
              protocol: TCP
              hostPort: 4317
            - name: otlp-http
              containerPort: 4318
              protocol: TCP
              hostPort: 4318
          env:
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: K8S_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: KUBE_POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: KUBE_NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName
            - name: CORALOGIX_PRIVATE_KEY
              valueFrom:
                secretKeyRef:
                  key: PRIVATE_KEY
                  name: coralogix-keys
          readinessProbe:
            httpGet:
              path: /
              port: 13133
          volumeMounts:
            - mountPath: /conf
              name: opentelemetry-collector-configmap
            - mountPath: /etc/otelcol-contrib/supervisor.yaml
              subPath: supervisor.yaml
              readOnly: true
              name: aml-opentelemetry-collector-supervisor
            - name: varlogpods
              mountPath: /var/log/pods
              readOnly: true
            - name: varlibdockercontainers
              mountPath: /var/lib/docker/containers
              readOnly: true
      volumes:
        - name: opentelemetry-collector-configmap
          configMap:
            name: aml-opentelemetry-collector-agent
            items:
              - key: relay
                path: relay.yaml
        - name: aml-opentelemetry-collector-supervisor
          configMap:
            name: aml-opentelemetry-collector-supervisor
            items:
              - key: supervisor.yaml
                path: supervisor.yaml
        - name: varlogpods
          hostPath:
            path: /var/log/pods
        - name: varlibdockercontainers
          hostPath:
            path: /var/lib/docker/containers
      nodeSelector:
        kubernetes.io/os: linux
      hostNetwork: false
