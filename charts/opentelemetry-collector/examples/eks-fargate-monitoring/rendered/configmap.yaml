---
# Source: opentelemetry-collector/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: cx-otel-collector-monitor
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-collector-0.119.11
    app.kubernetes.io/name: cx-otel-collector-monitor
    app.kubernetes.io/instance: example
    app.kubernetes.io/version: "0.131.1"
    app.kubernetes.io/managed-by: Helm
    
data:
  relay: |
    exporters:
      coralogix:
        application_name: otel-fargate-integration
        application_name_attributes:
        - k8s.namespace.name
        - service.namespace
        domain: eu2.coralogix.com
        logs:
          headers:
            X-Coralogix-Distribution: helm-otel-integration/
        metrics:
          headers:
            X-Coralogix-Distribution: helm-otel-integration/
        private_key: ${env:CORALOGIX_PRIVATE_KEY}
        profiles:
          headers:
            X-Coralogix-Distribution: helm-otel-integration/
        subsystem_name: eks-fargate
        subsystem_name_attributes:
        - k8s.deployment.name
        - k8s.statefulset.name
        - k8s.daemonset.name
        - k8s.cronjob.name
        - k8s.job.name
        - k8s.container.name
        - k8s.node.name
        - service.name
        timeout: 30s
        traces:
          headers:
            X-Coralogix-Distribution: helm-otel-integration/
      debug: {}
    extensions:
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
      k8s_observer:
        auth_type: serviceAccount
        observe_nodes: true
        observe_pods: true
    processors:
      batch:
        send_batch_max_size: 2048
        send_batch_size: 1024
        timeout: 60s
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      resource/metadata:
        attributes:
        - action: upsert
          key: k8s.cluster.name
          value: 'my-eks-fargate-cluster'
      resourcedetection/env:
        detectors:
        - system
        - env
        override: false
        system:
          resource_attributes:
            host.id:
              enabled: true
        timeout: 2s
      resourcedetection/region:
        detectors:
        - gcp
        - ec2
        - azure
        - eks
        eks:
          node_from_env_var: K8S_NODE_NAME
        override: true
        timeout: 2s
      transform/prometheus:
        error_mode: ignore
        metric_statements:
        - context: metric
          statements:
          - replace_pattern(metric.name, "_total$", "") where resource.attributes["service.name"]
            == "opentelemetry-collector"
          - replace_pattern(metric.name, "^otelcol_process_cpu_seconds_seconds$", "otelcol_process_cpu_seconds")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(metric.name, "^otelcol_process_memory_rss_bytes$", "otelcol_process_memory_rss_bytes")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(metric.name, "^otelcol_process_runtime_heap_alloc_bytes_bytes$",
            "otelcol_process_runtime_heap_alloc_bytes") where resource.attributes["service.name"]
            == "opentelemetry-collector"
          - replace_pattern(metric.name, "^otelcol_process_runtime_total_alloc_bytes_bytes$",
            "otelcol_process_runtime_total_alloc_bytes") where resource.attributes["service.name"]
            == "opentelemetry-collector"
          - replace_pattern(metric.name, "^otelcol_process_runtime_total_sys_memory_bytes_bytes$",
            "otelcol_process_runtime_total_sys_memory_bytes") where resource.attributes["service.name"]
            == "opentelemetry-collector"
          - replace_pattern(metric.name, "^otelcol_fileconsumer_open_files$", "otelcol_fileconsumer_open_files_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(metric.name, "^otelcol_fileconsumer_reading_files$", "otelcol_fileconsumer_reading_files_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(metric.name, "^otelcol_otelsvc_k8s_ip_lookup_miss$", "otelcol_otelsvc_k8s_ip_lookup_miss_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(metric.name, "^otelcol_otelsvc_k8s_pod_added$", "otelcol_otelsvc_k8s_pod_added_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(metric.name, "^otelcol_otelsvc_k8s_pod_table_size_ratio$",
            "otelcol_otelsvc_k8s_pod_table_size_ratio") where resource.attributes["service.name"]
            == "opentelemetry-collector"
          - replace_pattern(metric.name, "^otelcol_otelsvc_k8s_pod_updated$", "otelcol_otelsvc_k8s_pod_updated_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(metric.name, "^otelcol_otelsvc_k8s_pod_deleted$", "otelcol_otelsvc_k8s_pod_deleted_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(metric.name, "^otelcol_processor_filter_spans\\.filtered$",
            "otelcol_processor_filter_spans.filtered_ratio") where resource.attributes["service.name"]
            == "opentelemetry-collector"
        - context: resource
          statements:
          - set(attributes["k8s.pod.ip"], attributes["net.host.name"]) where attributes["service.name"]
            == "opentelemetry-collector"
          - delete_key(attributes, "service_name") where attributes["service.name"] ==
            "opentelemetry-collector"
        - context: datapoint
          statements:
          - delete_key(attributes, "service_name") where resource.attributes["service.name"]
            == "opentelemetry-collector"
          - delete_key(attributes, "otel_scope_name") where attributes["service.name"]
            == "opentelemetry-collector"
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
            max_recv_msg_size_mib: 20
          http:
            endpoint: ${env:MY_POD_IP}:4318
      prometheus:
        config:
          scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 30s
            static_configs:
            - targets:
              - ${env:MY_POD_IP}:8888
      receiver_creator:
        receivers:
          kubeletstats:
            config:
              auth_type: serviceAccount
              collection_interval: 30s
              endpoint: '`endpoint`:`kubelet_endpoint_port`'
              extra_metadata_labels:
              - container.id
              insecure_skip_verify: true
              metric_groups:
              - container
              - pod
              - node
            rule: type == "k8s.node" && labels["OTEL-collector-node"] == "true"
        watch_observers:
        - k8s_observer
    service:
      extensions:
      - health_check
      - k8s_observer
      pipelines:
        metrics/colmon:
          exporters:
          - coralogix
          processors:
          - memory_limiter
          - resource/metadata
          - resourcedetection/region
          - resourcedetection/env
          receivers:
          - receiver_creator
      telemetry:
        logs:
          encoding: json
        metrics:
          readers:
          - pull:
              exporter:
                prometheus:
                  host: ${env:MY_POD_IP}
                  port: 8888
