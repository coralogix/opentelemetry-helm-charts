---
# Source: opentelemetry-collector/templates/configmap-agent.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: example-opentelemetry-collector-agent
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-collector-0.119.6
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: example
    app.kubernetes.io/version: "0.131.1"
    app.kubernetes.io/managed-by: Helm
    
data:
  relay: |
    exporters:
      debug: {}
    extensions:
      file_storage:
        directory: /var/lib/otelcol
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
    processors:
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      transform/prometheus:
        error_mode: ignore
        metric_statements:
        - context: metric
          statements:
          - replace_pattern(name, "_total$", "") where resource.attributes["service.name"]
            == "opentelemetry-collector"
          - replace_pattern(name, "^otelcol_process_cpu_seconds_seconds$", "otelcol_process_cpu_seconds")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(name, "^otelcol_process_memory_rss_bytes$", "otelcol_process_memory_rss_bytes")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(name, "^otelcol_process_runtime_heap_alloc_bytes_bytes$",
            "otelcol_process_runtime_heap_alloc_bytes") where resource.attributes["service.name"]
            == "opentelemetry-collector"
          - replace_pattern(name, "^otelcol_process_runtime_total_alloc_bytes_bytes$",
            "otelcol_process_runtime_total_alloc_bytes") where resource.attributes["service.name"]
            == "opentelemetry-collector"
          - replace_pattern(name, "^otelcol_process_runtime_total_sys_memory_bytes_bytes$",
            "otelcol_process_runtime_total_sys_memory_bytes") where resource.attributes["service.name"]
            == "opentelemetry-collector"
          - replace_pattern(name, "^otelcol_fileconsumer_open_files$", "otelcol_fileconsumer_open_files_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(name, "^otelcol_fileconsumer_reading_files$", "otelcol_fileconsumer_reading_files_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(name, "^otelcol_otelsvc_k8s_ip_lookup_miss$", "otelcol_otelsvc_k8s_ip_lookup_miss_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(name, "^otelcol_otelsvc_k8s_pod_added$", "otelcol_otelsvc_k8s_pod_added_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(name, "^otelcol_otelsvc_k8s_pod_table_size_ratio$", "otelcol_otelsvc_k8s_pod_table_size_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(name, "^otelcol_otelsvc_k8s_pod_updated$", "otelcol_otelsvc_k8s_pod_updated_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(name, "^otelcol_otelsvc_k8s_pod_deleted$", "otelcol_otelsvc_k8s_pod_deleted_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
          - replace_pattern(name, "^otelcol_processor_filter_spans\\.filtered$", "otelcol_processor_filter_spans.filtered_ratio")
            where resource.attributes["service.name"] == "opentelemetry-collector"
        - context: resource
          statements:
          - set(attributes["k8s.pod.ip"], attributes["net.host.name"]) where attributes["service.name"]
            == "opentelemetry-collector"
          - delete_key(attributes, "service_name") where attributes["service.name"] ==
            "opentelemetry-collector"
        - context: datapoint
          statements:
          - delete_key(attributes, "service_name") where resource.attributes["service.name"]
            == "opentelemetry-collector"
          - delete_key(attributes, "otel_scope_name") where attributes["service.name"]
            == "opentelemetry-collector"
    receivers:
      filelog:
        exclude:
        - C:\var\log\pods\default_example-opentelemetry-collector*_*\opentelemetry-collector\*.log
        force_flush_period: 0
        include:
        - C:\var\log\pods\*\*\*.log
        include_file_name: false
        include_file_path: true
        operators:
        - id: get-format
          routes:
          - expr: body matches "^\\{"
            output: parser-docker
          - expr: body matches "^[^ Z]+ "
            output: parser-crio
          - expr: body matches "^[^ Z]+Z"
            output: parser-containerd
          type: router
        - id: parser-crio
          regex: ^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
          timestamp:
            layout: 2006-01-02T15:04:05.999999999Z07:00
            layout_type: gotime
            parse_from: attributes.time
          type: regex_parser
        - combine_field: attributes.log
          combine_with: ""
          id: crio-recombine
          is_last_entry: attributes.logtag == 'F'
          max_batch_size: 1000
          max_log_size: 1048576
          output: handle_empty_log
          source_identifier: attributes["log.file.path"]
          type: recombine
        - id: parser-containerd
          regex: ^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: attributes.time
          type: regex_parser
        - combine_field: attributes.log
          combine_with: ""
          id: containerd-recombine
          is_last_entry: attributes.logtag == 'F'
          max_batch_size: 1000
          max_log_size: 1048576
          output: handle_empty_log
          source_identifier: attributes["log.file.path"]
          type: recombine
        - id: parser-docker
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: attributes.time
          type: json_parser
        - combine_field: attributes.log
          combine_with: ""
          id: docker-recombine
          is_last_entry: attributes.log endsWith "\n"
          max_batch_size: 1000
          max_log_size: 1048576
          output: handle_empty_log
          source_identifier: attributes["log.file.path"]
          type: recombine
        - field: attributes.log
          id: handle_empty_log
          if: attributes.log == nil
          type: add
          value: ""
        - parse_from: attributes["log.file.path"]
          regex: ^C:\\var\\log\\pods\\(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[^\/]+)\\(?P<container_name>[^\._]+)\\(?P<restart_count>\d+)\.log$
          type: regex_parser
        - from: attributes.stream
          to: attributes["log.iostream"]
          type: move
        - from: attributes.container_name
          to: resource["k8s.container.name"]
          type: move
        - from: attributes.namespace
          to: resource["k8s.namespace.name"]
          type: move
        - from: attributes.pod_name
          to: resource["k8s.pod.name"]
          type: move
        - from: attributes.restart_count
          to: resource["k8s.container.restart_count"]
          type: move
        - from: attributes.uid
          to: resource["k8s.pod.uid"]
          type: move
        - from: attributes.log
          id: clean-up-log-record
          to: body
          type: move
        - id: export
          type: noop
        retry_on_failure:
          enabled: true
        start_at: beginning
        storage: file_storage
      hostmetrics:
        collection_interval: 10s
        scrapers:
          cpu:
            metrics:
              system.cpu.utilization:
                enabled: true
          disk: null
          filesystem: null
          load: null
          memory:
            metrics:
              system.memory.utilization:
                enabled: true
          network: null
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
            max_recv_msg_size_mib: 20
          http:
            endpoint: ${env:MY_POD_IP}:4318
      prometheus:
        config:
          scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 30s
            static_configs:
            - targets:
              - ${env:MY_POD_IP}:8888
    service:
      extensions:
      - health_check
      - file_storage
      pipelines:
        logs:
          exporters:
          - debug
          processors:
          - memory_limiter
          receivers:
          - filelog
          - otlp
        metrics:
          exporters:
          - debug
          processors:
          - memory_limiter
          - transform/prometheus
          receivers:
          - hostmetrics
          - prometheus
          - otlp
        traces:
          exporters:
          - debug
          processors:
          - memory_limiter
          receivers:
          - otlp
      telemetry:
        logs:
          encoding: json
        metrics:
          readers:
          - pull:
              exporter:
                prometheus:
                  host: ${env:MY_POD_IP}
                  port: 8888
